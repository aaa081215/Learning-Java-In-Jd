# Elasticsearch数据存储机制及性能瓶颈分析


本文结合案例问题及分析过程和结果，来探讨Elasticesarch的bulk性能瓶颈以及产生性能瓶颈的原因分析

## 案例分析
最近做了一次kafka的升级，版本从0.8升级到0.10，只是改变了消费数据的方式，并未修改实际业务逻辑，但升级完成后发现,部分数据据在进行bulk后，会有部分字段丢失的现象，分析日志后发现。
例如在同一批次中存在如下数据：

{id:1,dispatch_create_pin:null,status:1}
{id:1,dispatch_create_pin:ceshi,status:2}
{id:1,status:3}

出现的结果是，dispatch_create_pin=ceshi实际并未存入es，而status的状态却更新成了3。

针对以上问题，我们首先应了解ElasticSearch官方有说明，ElasticSearch只是一种近实时的解决方案，数据从写入缓存文件到可读有个默认1秒的fresh时间差，下面我们详细的分析ElasticSearch的文档写入到可读的整个过程。
##ElasticSearch内部存储及索引机制
和传统的数据库不同，在ElasticSearch中，每个字段里面的每个单词都是可以被搜索的，为了支持这个特性，es中会维护一个叫做“invertedindex”（也叫逆向索引）的表，表内包含了所有文档中出现的所有单词，同时记录了这个单词在哪个文档中出现过
逆向索引里面不止记录了单词与文档的对应关系，它还维护了很多其他有用的数据。如：每个文档一共包含了多少个单词，单词在不同文档中的出现频率，每个文档的长度，所有文档的总长度等等。这些数据用来给搜索结果进行打分，如搜索单词apple时，那么出现apple这个单词次数最多的文档会被优先返回，因为它匹配的次数最多，和我们的搜索条件关联性最大，因此得分也最多。

 

逆向索引是不可更改的，一旦它被建立了，里面的数据就不会再进行更改。这样做就带来了以下几个好处：

-- 不需要给逆向索引加锁，因为不允许被更改，只有读操作，所以就不用考虑多线程导致互斥等问题。

-- 索引一旦被加载到了缓存中，大部分访问操作都是对内存的读操作，省去了访问磁盘带来的io开销。

-- 因为逆向索引的不可变性，所有基于该索引而产生的缓存也不需要更改，因为没有数据变更。

-- 使用逆向索引可以压缩数据，减少磁盘io及对内存的消耗。

   既然逆向索引是不可更改的，那么如何添加新的数据，删除数据以及更新数据？为了解决这个问题，lucene将一个大的逆向索引拆分成了多个小的段segment。每个segment本质上就是一个逆向索引。在lucene中，同时还会维护一个文件commit point，用来记录当前所有可用的segment，当我们在这个commit point上进行搜索时，就相当于在它下面的segment中进行搜索，每个segment返回自己的搜索结果，然后进行汇总返回给用户。
   
-- 新增的文档首先会被存放在内存的缓存中

-- 当文档数足够多或者到达一定时间点时，就会对缓存进行commit

-- 生成一个新的segment，并写入磁盘

-- 生成一个新的commit point，记录当前所有可用的segment

-- 等待所有数据都已写入磁盘

-- 打开新增的segment，这样我们就可以对新增的文档进行搜索了

-- 清空缓存，准备接收新的文档
### Refresh

ES的一个特性就是提供实时搜索，新增加的文档可以在很短的时间内就被搜索到。在创建一个commit point时，为了确保所有的数据都已经成功写入磁盘，避免因为断电等原因导致缓存中的数据丢失，在创建segment时需要一个fsync的操作来确保磁盘写入成功。但是如果每次新增一个文档都要执行一次fsync就会产生很大的性能影响。在文档被写入segment之后，segment首先被写入了文件系统的缓存中，这个过程仅使用很少的资源。之后segment会从文件系统的缓存中逐渐flush到磁盘，这个过程时间消耗较大。但是实际上存放在文件缓存中的文件同样可以被打开读取。ES利用这个特性，在segment被commit到磁盘之前，就打开对应的segment，这样存放在这个segment中的文档就可以立即被搜索到了。

在ES中，将缓存中的文档写入segment，并打开segment使之可以被搜索的过程叫做refresh。默认情况下，分片的refresh频率是每秒1次。这就解释了为什么es声称提供实时搜索功能，新增加的文档会在1s内就可以进行搜索了。

Refresh的频率通过index.refresh_interval:100s参数控制，一条新写入es的日志，在进行refresh之前，是在es中不能立即搜索不到的。

通过执行curl -XPOST127.0.0.1:9200/_refresh，可以手动触发refresh行为。
##flush与translog
refresh行为会立即把缓存中的文档写入segment中，但是此时新创建的segment是写在文件系统的缓存中的。如果出现断电等异常，那么这部分数据就丢失了。所以es会定期执行flush操作，将缓存中的segment全部写入磁盘并确保写入成功，同时创建一个commit point，整个过程就是一个完整的commit过程。

但是如果断电的时候，缓存中的segment还没有来得及被commit到磁盘，那么数据依旧会产生丢失。为了防止这个问题，es中又引入了translog文件。

--每当es接收一个文档时，在把文档放在buffer的同时，都会把文档记录在translog中

--执行refresh操作时，会将缓存中的文档写入segment中，但是此时segment是放在缓存中的，并没有落入磁盘，此时新创建的segment是可以进行搜索的。

--按照如上的流程，新的segment继续被创建，同时这期间新增的文档会一直被写到translog中。

--当达到一定的时间间隔，或者translog足够大时，就会执行commit行为，将所有缓存中的segment写入磁盘。确保写入成功后，translog就会被清空。

执行commit并清空translog的行为，在es中可以通过_flush api进行手动触发。

如：

curl -XPOST127.0.0.1:9200/tcpflow-2015.06.17/_flush?v

通常这个flush行为不需要人工干预，交给es自动执行就好了。同时，在重启es或者关闭索引之间，建议先执行flush行为，确保所有数据都被写入磁盘，避免照成数据丢失。通过调用sh service.sh start/restart，会自动完成flush操作。