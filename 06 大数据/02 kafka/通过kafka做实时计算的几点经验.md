# 通过kafka做实时计算的几点经验
## JDQ
大数据平台的kafka产品，除非场景特别，满足绝大多数系统kafka服务需要。
## 讨论范围
限于kafkaAPI使用正常（或是JDQ配置正确）的前提下，一些开发配置或编程的注意事项。
api本身的使用或JDQ配置可以参考官方文档及JDQ平台文档。
## 正文
### 顺序
kafka流水式的数据记录方式保证了消费/发送信息的有序，服务端和消费端为此无需做什么额外的工作。

jmq则因为客户端会默认启用至少3个线程，使得数据顺序（特别是来自数据库的数据）有可能和执行顺序不同。

如果对顺序有较强的要求（比如准备通过kafka同步一张数据库表），又对kafka和jmq的两种数据接入方式不太确定，可以优先考虑kafka。

PS：binlake3.0平台通过kafka中转，在平台端控制同一业务主键数据在未消费时单条下发，保证到达jmq的数据顺序可靠。
### 计算服务幂等
kafka默认消息被至少被消费一次，也就是说并不保证数据的消费操作执行且只执行一次，因此计算服务需要保证幂等。

另一方面数据位点重置也是kafka的一大优势，幂等的计算服务在位点重置的时候风险也更小。

如果期望kafka消费端是exactly-once的，最好通过业务逻辑处理（比如记录一个短时效的缓存标识），不能完全依靠消息系统的机制，无论实际使用的是jmq还是kafka。

PS：kafka官方文档提及的exactly-once需要消费端自行控制，目前网上实现方案多数都基于事务控制，但是实际的代码不一定涵盖了对位点的ack操作，在数据处理-位点提交这一步有潜在的风险，所以保证计算服务幂等是最可靠的选择。
### 存储服务insertOrUpdate
理由同上，如果计算过程存在对存储的写操作，需要支持覆盖，否则需要业务逻辑上做额外的处理。

### 互相依赖的计算服务兼容乱序
两个独立的实时计算服务如果存在逻辑上的依赖关系，需要考虑不同数据源乱序下发的场景。

例如做一个分拣中心已分拣未发货运单的计算：
- 分拣数据源：dms_sorting
- 发货数据源：dms_send

从业务场景来说，同一运单同一个分拣中心的分拣操作一定在发货操作之前，所以dms_sorting操作的数据下发一定在dms_send之前，计算只需要考虑这个顺序的判断逻辑。

但在实际场景中，因为重置位点、操作上传晚、数据积压、网络延迟等等因素，同一个运单dms_send这个更晚的操作很可能先下发到系统，dms_sorting这个实际上操作时间更早的数据则在它之后才进入计算服务。 那么计算逻辑就要考虑兼容两种顺序（通常的做法是互写），保证最后的计算结果符合预期。

### kafka服务端数据保存周期
kafka的消息是无状态的，利用硬盘连续写/连续读的特性保障性能，相对基于jms规范的消息服务，kafka服务对硬盘有较重的资源占用需求。

由于以上原因，kafka报文数据的存储周期和大小是有限制的，默认为7天。如果因为业务场景的要求需要更长的报文数据存储周期或空间，考虑其他组件技术更佳，否则对服务端硬盘资源的消耗会很严重。

### 分区
一个分组中kafka的一个消费端实例对应一个分区，因此：
- 假如消费端实例比分区更多，多余的消费端实例只能起到故障容灾的作用。
- 假如消费端实例和分区数一样，一个消费端对应一个分区。
- 假如消费端实例比分区更少，会有一个消费端消费多个分区的数据。

以下行为在实际使用中造成了很多问题，请注意避免：
- 如果一个计算服务接入了多个kafka数据源，那么在消费实例启用时要注意不要使用类似list.iterator().next()的方式获取未消费分区。 因为不同数据源的分区数量通常不同，这会导致最先启动的实例一定消费了全部数据源的分区，而后启动的数据源则根据分区数量由多到少分担了计算的压力，最好理想的选择就是一个计算实例只处理一个数据源。
- 无论分支如何复杂，一个计算服务中千万千万注意ack只能有一次，否则可能因为计算时间的差异导致位点重复提交，最后表现为分区位点漂移，此场景细节参考kafka虚假积压中的描述。
- 分区的划分在服务端还涉及硬件资源配置，因此如果有分区扩充需要，请提前和kafka系统的管理方沟通，预留出硬件资源调配的时间。
- kafka服务端只记录了一份实际的报文正文，不同客户端分组的差异只是在权限和位点的管理。所以如果一个数据源有多个分组用户，扩充分区的操作影响到所有用户的消费，需要等待所有用户做好扩充分区的准备才能进行。也要留意kafka服务端发布的分区扩容通知，评估是否会对自己造成影响。
