# 贝叶斯信念网络 #
--------------

**朴素贝叶斯分类**有一个限制条件，就是假定类条件独立（即给定元组的类标号，假定属性的值可以条件地相互独立）。当这个条件成立时，朴素贝叶斯分类法的准确率是最高的。然而，在实践中，变量（属性）之间可能存在依赖关系，这样就限制了朴素贝叶斯分类的能力。贝叶斯信念网络说明联合条件概率分布，它提供一种因果关系的图形模型，可以在其上进行学习。它不要求所有的属性集都条件独立，而允许一部分属性条件独立。训练后的贝叶斯信念网络可以用于分类。

## 1. 概念和机制##

   为了简便，后面都用信念网络代替。

   信念网络由两部分定义——**有向无环图（DAG）**和**条件概率表（CPT）**

（1）**有向无环图**：其每个结点代表一个随机变量。变量可以是离散值的或连续值的，它们可能对应于给定数据中的实际属性，或对应于相信形成联系的“隐藏变量“（例如，在医疗数据中，隐藏变量可以预示由多种症状表示的综合病症，刻画一种具体的疾病）。而每条弧代表一个概率依赖。如果一条弧由结点Y到Z，则Y是Z的双亲或直接前驱，而Z是Y的后继。

（2）**条件概率表**：每个变量（属性）都有一个条件概率表。变量Y的CPT说明条件分布P(Y|Parents(Y))，其中Parents(Y)是Y的双亲。

   贝叶斯信念网络的重要性质：给定其双亲，每个变量条件独立于图中它的非后代。

  **例子（一个6个布尔变量的简单信念网络）** ：

![](https://raw.githubusercontent.com/shengjielai/bigdata_image/master/lungcancer.jpg)


   注意，倘若已知患者得了肺癌，变量PositiveXRay独立于该患者是否具有家庭肺癌史，也独立于它是否吸烟。换言之，一旦我们知道变量LungCancer的结果，那么变量FamilyHistory和Smoker就不再提供关于PositiveXRay的任何附加信息。这些弧还表明：给定其双亲FamilyHistory和Smoker，变量LungCancer条件独立于Emphysema（LungCancer唯一的非后代）。

   图b显示了变量LungCancer的CPT。从左上角和右下角的表目，我们可以看到：

    P(LungCancer=yes|FamilyHistory=yes,Smoker=yes)=0.8

    P(LungCancer=no|FamilyHistory=no,Smoker=no)=0.9

  设 X=(x1,x2, ..., xn) 是被属性 Y1,..., Yn
   描述的数据元组。则联合概率分布:

<img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P({x_1},{x_2},...,{x_n}) = \prod\limits_{i = 1}^n {P({x_i}|parents({Y_i}))} 
 " style="border:none;">

 其中，P(x1, x2, ...,
  xn)是X的值的特定组合的概率，而P(xi | parents(Yi))的值对应于Yi的CPT的表目。


 如上图，对于FamilyHistory，Smoker，LungCancer这三个属性，用朴素贝叶斯计算，得到的联合概率是:

<img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P('FamilyHistory') \times P('Smo\ker ') \times P('LungCancer')
 " style="border:none;">

 但是如果用贝叶斯信念网络计算得到的联合概率将会是：

<img src="http://chart.googleapis.com/chart?cht=tx&chl=\Large P('FamilyHistory') \times P('Smo\ker ') \times P('LungCancer'|('FamilyHistory','Smo\ker '))
 " style="border:none;">

，会更为准确。


网络内的节点可选作“输出”节点，代表类标号属性，可有多个输出节点。多种推断和学习算法都可以用于这种网络。分类过程不是返回单个类标号，而是返回概率分布，给出每个类的概率。
## 2. 训练贝叶斯信念网络 ##

构造与训练贝叶斯网络分为以下两步（也就是说，给你一个训练元组，要用贝叶斯信念网络进行分类，需要做的事）：

(1)确定随机变量间的拓扑关系，形成DAG。这一步通常需要领域专家完成，而想要建立一个好的拓扑结构，通常需要不断迭代和改进才可以。

(2)训练贝叶斯网络。这一步也就是要完成条件概率表的构造，如果每个随机变量的值都是可以直接观察的，那么这一步的训练是直观的，方法类似于朴素贝叶斯分类。但是通常贝叶斯网络中存在隐藏变量节点，那么训练方法就是比较复杂，例如可使用**梯度下降法**。
