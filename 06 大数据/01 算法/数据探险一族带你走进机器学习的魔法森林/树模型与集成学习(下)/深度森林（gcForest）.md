# 深度森林（gcForest） #
深度森林（gcForest）是一种基于决策树的集成方法，首次问世于周志华教授和冯霁博士在2017年2月28日发表的论文中，《Deep Forest: Towards An Alternative to Deep Neural Networks》，文中作者提出“深度森林”是一种可以与深度神经网络相媲美的基于树的深度学习模型，性能较之深度神经网络有很强的竞争力。
尽管深度学习有很令人惊叹的应用，但同时它也有不足之处，主要表现为：
1. 深度学习需要使用大量的数据进行训练。哪怕是现在的大数据时代，我们都缺乏足够的训练数据——因为标注类别是成本很高的事情。
2. 深度学习因其复杂难懂的结构和庞大的计算能力需求，一定程度上使得很多尝试被迫“知难而退”——因为商业应用上不只追求正确，更重要的是计算效率，科技公司是坚决不干成本高的事情。
3. 深度学习有很多超参数，而且这些超参数对模型结果有着至关重要的影响，所以对超参数的选取也是个很重要的事情——超参数就好比如一首歌曲中的节拍、强弱、速度等因素，即便音符一模一样，但这些因素的不一样就会产生不同的效果。
深度神经网络需要花大力气调参，相比之下gcForest要容易训练得多。实际上，在几乎完全一样的超参数设置下，gcForest 在处理不同领域（domain）的不同数据时，也能达到极佳的性能。gcForest由级联深林（Cascade Forest）和多粒度扫描（Multi-Grained Scanning）两部分构成，以下分别介绍。
## 一、级联森林（Cascade Forest） ##
级联森林结构的图示。级联的每个级别包括两个随机森林（random forests以蓝色字体标出）和两个完全随机树木森林（complete-random tree forests以黑色字体标出）。假设有三个类要预测；因此，每个森林将输出三维类向量，然后将其连接以重新表示原始输入。注意，要将前一级的特征和这一级的特征连接在一起。

![](https://raw.githubusercontent.com/xuwenfeng0459/image/master/13.png)

图1 级联模型的结构框图

在原始论文的具体实现中，每个完全随机的树森林包含1000个完全随机树，每棵树通过随机选择一个特征在树的每个节点进行分割实现生成，一直生长到每个叶节点只包含相同类的实例或不超过10个实例。类似地，每个随机森林也包含1000棵树，每颗树在原始特征中随机选择sqrt(d) 数量的特征作为候选特征，其中d是原始特征向量的维度；然后根据gini 指数选择特征和分割点。
给定一个实例（或样本），每个森林会通过计算在相关实例落入的叶节点处的不同类的训练样本的百分比，然后对森林中的所有树计平均值，以生成对类的分布的估计。如图2所示，其中红色部分突出了每个实例遍历到叶节点的路径，叶节点中的不同标记表示了不同的类。

![](https://raw.githubusercontent.com/xuwenfeng0459/image/master/14.png)

图2 类向量的生成过程

被估计的类分布形成类向量（class vector），该类向量接着与输入到级联的下一级的原始特征向量相连接。例如，假设有三个类，则四个森林每一个都将产生一个三维的类向量，因此，级联的下一级将接收12 = 3×4个增强特征（augmented feature）。
## 二、多粒度扫描（Multi-Grained Scanning） ##
深度神经网络在处理特征关系方面是强大的，例如，卷积神经网络对图像数据有效，其中原始像素之间的空间关系是关键的。递归神经网络对序列数据有效，其中顺序关系是关键的。受这种认识的启发，我们用多粒度扫描流程来增强级联森林。图3所示多粒度扫描的结构框图。

![](https://raw.githubusercontent.com/xuwenfeng0459/image/master/15.png)

图3 多粒度扫描的结构框图
滑动窗口用于扫描原始特征。假设有400个原始特征，并且使用100个特征的窗口大小。对于序列数据，将通过滑动一个特征的窗口来生成100维的特征向量；总共产生301个特征向量。如果原始特征具有空间关系，比如图像像素为400的20×20的面板，则10×10窗口将产生121个特征向量（即121个10×10的面板）。从正/负训练样例中提取的所有特征向量被视为正/负实例；它们将被用于生成类向量：从相同大小的窗口提取的实例将用于训练完全随机树森林和随机森林，然后生成类向量并连接为转换后的像素。如上图的上半部分所示，假设有3个类，并且使用100维的窗口；然后，每个森林产生301个三维类向量，导致对应于原始400维原始特征向量的1,806维变换特征向量。
## 三、gcForest整体结构 ##
gcForest的整体结构如图4所示，通过使用多个尺寸的滑动窗口，最终的变换特征矢量将包括更多的特征。然后在将特征向量concat成一个3618-dim的原始数据，表示原始的一个数据样本，第一级的输出是12+3618=3630，后面也是一样，直到最后第N级，只有12个输出，然后在每一类别上做avg，然后输出max那一类的label，那就是最终的预测类别。

![](https://raw.githubusercontent.com/xuwenfeng0459/image/master/16.png)

图4 gcForest整体流程

## 结论： ##
与深度神经网络相比，gcForest在我们的实验中表现了极高的竞争力或更好的性能。更重要的是，gcForest 具有少得多的超参数，并且对参数设置不太敏感；gcForest 的训练过程效率高且可扩展。它在一台 PC 上的训练时间和在 GPU 设施上跑的深度神经网络差不多，有鉴于 gcForest 天然适用于并行的部署，其效率高的优势就更为明显。此外，深度神经网络需要大规模的训练数据，而 gcForest 在仅有小规模训练数据的情况下也照常运转。不仅如此，作为一种基于树的方法，gcForest 在理论分析方面也应当比深度神经网络更加容易。